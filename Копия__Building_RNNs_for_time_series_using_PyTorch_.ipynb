{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQio_c0uPA8e"
      },
      "source": [
        "# Building RNN, LSTM, and GRU for time series using PyTorch\n",
        "\n",
        "In this notebook, I'd like to give you a bit of an introduction to some of the RNN structures, such as RNN, LSTM, and GRU, and help you get started building your deep learning models for time-series forecasting using PyTorch. \n",
        "\n",
        "Due to PyTorch's recency, it has been somewhat difficult for me to find the relevant pieces of information and code samples from the get-go, which is usually a bit easier with frameworks that have been around for a while, say TensorFlow. So, I decided to put together the things I would have liked to know earlier. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bokE2pG_PHL_"
      },
      "source": [
        "## Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A5guw4joPA8q"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVPXtRk5PA8r"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "Well, I suppose we need some time-series data to start with. Be it payment transactions or stock exchange data, time-series data is everywhere. One such public dataset is [PJM's Hourly Energy Consumption data](https://www.kaggle.com/robikscube/hourly-energy-consumption), a univariate time-series dataset of 10+ years of hourly observations collected from different US regions. I'll be using the PJM East region data, which originally has the hourly energy consumption data from 2001 to 2018, but any of the datasets provided in the link should work.\n",
        "\n",
        "The following cell pops up an upload widget, so that you can upload your data to this notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qP8_XnAeGA4"
      },
      "source": [
        "If you'd like to work with a dataset other than _PJME_hourly.csv_, you can change the field in the next cell accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i3MRUAGwdAGe"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "df = pd.read_csv('C:\\PYTHON\\PythonLab5\\dataset.csv')\n",
        "df.columns = ['data', 'temp_day', 'wind', 'pressure_day', 'temp_even', 'pressure_even']  # 2\n",
        "\n",
        "nan_value = float(\"NaN\")                             # 3  ( null / None / Nan ) \n",
        "df.replace(\" \", nan_value, inplace=True)\n",
        "df = df.dropna()\n",
        "df[['temp_day', \"temp_even\"]] = df[['temp_day', \"temp_even\"]].astype(int) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GGa0XI3MPA8r"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "def plot_dataset(df, title):\n",
        "    data = []\n",
        "    \n",
        "    value = go.Scatter(\n",
        "        x=df.index,\n",
        "        y=df.value,\n",
        "        mode=\"lines\",\n",
        "        name=\"values\",\n",
        "        marker=dict(),\n",
        "        text=df.index,\n",
        "        line=dict(color=\"rgba(0,0,0, 0.3)\"),\n",
        "    )\n",
        "    data.append(value)\n",
        "\n",
        "    layout = dict(\n",
        "        title=title,\n",
        "        xaxis=dict(title=\"Date\", ticklen=5, zeroline=False),\n",
        "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
        "    )\n",
        "\n",
        "    fig = dict(data=data, layout=layout)\n",
        "    iplot(fig)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Y11jwqakPA8r",
        "outputId": "ae479848-78c1-4330-8d9a-f662b89997ea"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"None of ['data'] are in the columns\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mset_index([\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      2\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtemp_day\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m      4\u001b[0m df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df\u001b[39m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Python3.10.5\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Python3.10.5\\lib\\site-packages\\pandas\\core\\frame.py:6009\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6006\u001b[0m                 missing\u001b[39m.\u001b[39mappend(col)\n\u001b[0;32m   6008\u001b[0m \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m-> 6009\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of \u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m are in the columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6011\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   6012\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
            "\u001b[1;31mKeyError\u001b[0m: \"None of ['data'] are in the columns\""
          ]
        }
      ],
      "source": [
        "df = df.set_index(['data'])\n",
        "df = df.rename(columns={'temp_day': 'value'})\n",
        "\n",
        "df.index = pd.to_datetime(df.index)\n",
        "if not df.index.is_monotonic:\n",
        "    df = df.sort_index()\n",
        "    \n",
        "plot_dataset(df, title='PJM East (PJME) Region: estimated energy consumption in Megawatts (MW)')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dLb52VIPA8s"
      },
      "source": [
        "The next step is to generate feature columns to transform our univariate dataset into a multivariate dataset. We will convert this time series into a supervised learning problem if you will. In some datasets, such features as hourly temperature, humidity, or precipitation, are readily available. However, in our dataset, no extra information could help us predict the energy consumption is given. So, it falls to our lot to create such predictors, i.e., feature columns.\n",
        "\n",
        "I'll show you two popular ways to generate features: passing lagged observations as features and creating date time features from the DateTime index. Both approaches have their advantages and disadvantages, and each may prove more useful depending on the task at hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Rv3qDOPA8s"
      },
      "source": [
        "## Generating time-lagged observations\n",
        "\n",
        "Let's start with using time steps as features. In other words, we're trying to predict the next value, _X(t+n)_, from the previous n observations _Xt, X+1, …, and X(t+n-1)_. Then, what we need to do is simply creating n columns with the preceding observations. Luckily, Pandas provides the method _shift()_ to shift the values in a column. So, we can write a for loop to create such lagged observations by shifting the values in a column by n times and removing the first n columns.\n",
        "\n",
        "After setting the number of input features, i.e., lagged observations, to 100, we get the following DataFrame with 101 columns, one for the actual value, and the rest for the preceding 100 observations at each row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "Nol5_YZLPA8s",
        "outputId": "14157ef6-a2e9-4ddd-c026-0581d2e932c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-36-9686bd7878a4>:4: PerformanceWarning:\n",
            "\n",
            "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-90d512a4-4d46-485c-8f52-43835a9fb771\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>lag1</th>\n",
              "      <th>lag2</th>\n",
              "      <th>lag3</th>\n",
              "      <th>lag4</th>\n",
              "      <th>lag5</th>\n",
              "      <th>lag6</th>\n",
              "      <th>lag7</th>\n",
              "      <th>lag8</th>\n",
              "      <th>lag9</th>\n",
              "      <th>...</th>\n",
              "      <th>lag91</th>\n",
              "      <th>lag92</th>\n",
              "      <th>lag93</th>\n",
              "      <th>lag94</th>\n",
              "      <th>lag95</th>\n",
              "      <th>lag96</th>\n",
              "      <th>lag97</th>\n",
              "      <th>lag98</th>\n",
              "      <th>lag99</th>\n",
              "      <th>lag100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2002-01-05 05:00:00</th>\n",
              "      <td>26822.0</td>\n",
              "      <td>26669.0</td>\n",
              "      <td>27034.0</td>\n",
              "      <td>27501.0</td>\n",
              "      <td>28635.0</td>\n",
              "      <td>30924.0</td>\n",
              "      <td>33202.0</td>\n",
              "      <td>35368.0</td>\n",
              "      <td>36762.0</td>\n",
              "      <td>37539.0</td>\n",
              "      <td>...</td>\n",
              "      <td>30692.0</td>\n",
              "      <td>29943.0</td>\n",
              "      <td>29595.0</td>\n",
              "      <td>29308.0</td>\n",
              "      <td>28654.0</td>\n",
              "      <td>28057.0</td>\n",
              "      <td>27899.0</td>\n",
              "      <td>28357.0</td>\n",
              "      <td>29265.0</td>\n",
              "      <td>30393.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-05 06:00:00</th>\n",
              "      <td>27399.0</td>\n",
              "      <td>26822.0</td>\n",
              "      <td>26669.0</td>\n",
              "      <td>27034.0</td>\n",
              "      <td>27501.0</td>\n",
              "      <td>28635.0</td>\n",
              "      <td>30924.0</td>\n",
              "      <td>33202.0</td>\n",
              "      <td>35368.0</td>\n",
              "      <td>36762.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31395.0</td>\n",
              "      <td>30692.0</td>\n",
              "      <td>29943.0</td>\n",
              "      <td>29595.0</td>\n",
              "      <td>29308.0</td>\n",
              "      <td>28654.0</td>\n",
              "      <td>28057.0</td>\n",
              "      <td>27899.0</td>\n",
              "      <td>28357.0</td>\n",
              "      <td>29265.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-05 07:00:00</th>\n",
              "      <td>28557.0</td>\n",
              "      <td>27399.0</td>\n",
              "      <td>26822.0</td>\n",
              "      <td>26669.0</td>\n",
              "      <td>27034.0</td>\n",
              "      <td>27501.0</td>\n",
              "      <td>28635.0</td>\n",
              "      <td>30924.0</td>\n",
              "      <td>33202.0</td>\n",
              "      <td>35368.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31496.0</td>\n",
              "      <td>31395.0</td>\n",
              "      <td>30692.0</td>\n",
              "      <td>29943.0</td>\n",
              "      <td>29595.0</td>\n",
              "      <td>29308.0</td>\n",
              "      <td>28654.0</td>\n",
              "      <td>28057.0</td>\n",
              "      <td>27899.0</td>\n",
              "      <td>28357.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-05 08:00:00</th>\n",
              "      <td>29709.0</td>\n",
              "      <td>28557.0</td>\n",
              "      <td>27399.0</td>\n",
              "      <td>26822.0</td>\n",
              "      <td>26669.0</td>\n",
              "      <td>27034.0</td>\n",
              "      <td>27501.0</td>\n",
              "      <td>28635.0</td>\n",
              "      <td>30924.0</td>\n",
              "      <td>33202.0</td>\n",
              "      <td>...</td>\n",
              "      <td>31031.0</td>\n",
              "      <td>31496.0</td>\n",
              "      <td>31395.0</td>\n",
              "      <td>30692.0</td>\n",
              "      <td>29943.0</td>\n",
              "      <td>29595.0</td>\n",
              "      <td>29308.0</td>\n",
              "      <td>28654.0</td>\n",
              "      <td>28057.0</td>\n",
              "      <td>27899.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-01-05 09:00:00</th>\n",
              "      <td>31241.0</td>\n",
              "      <td>29709.0</td>\n",
              "      <td>28557.0</td>\n",
              "      <td>27399.0</td>\n",
              "      <td>26822.0</td>\n",
              "      <td>26669.0</td>\n",
              "      <td>27034.0</td>\n",
              "      <td>27501.0</td>\n",
              "      <td>28635.0</td>\n",
              "      <td>30924.0</td>\n",
              "      <td>...</td>\n",
              "      <td>30360.0</td>\n",
              "      <td>31031.0</td>\n",
              "      <td>31496.0</td>\n",
              "      <td>31395.0</td>\n",
              "      <td>30692.0</td>\n",
              "      <td>29943.0</td>\n",
              "      <td>29595.0</td>\n",
              "      <td>29308.0</td>\n",
              "      <td>28654.0</td>\n",
              "      <td>28057.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 20:00:00</th>\n",
              "      <td>44057.0</td>\n",
              "      <td>45641.0</td>\n",
              "      <td>46760.0</td>\n",
              "      <td>46816.0</td>\n",
              "      <td>46989.0</td>\n",
              "      <td>47154.0</td>\n",
              "      <td>46534.0</td>\n",
              "      <td>45372.0</td>\n",
              "      <td>43954.0</td>\n",
              "      <td>42189.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28389.0</td>\n",
              "      <td>30789.0</td>\n",
              "      <td>33747.0</td>\n",
              "      <td>36581.0</td>\n",
              "      <td>37870.0</td>\n",
              "      <td>39089.0</td>\n",
              "      <td>40517.0</td>\n",
              "      <td>40709.0</td>\n",
              "      <td>39906.0</td>\n",
              "      <td>38637.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 21:00:00</th>\n",
              "      <td>43256.0</td>\n",
              "      <td>44057.0</td>\n",
              "      <td>45641.0</td>\n",
              "      <td>46760.0</td>\n",
              "      <td>46816.0</td>\n",
              "      <td>46989.0</td>\n",
              "      <td>47154.0</td>\n",
              "      <td>46534.0</td>\n",
              "      <td>45372.0</td>\n",
              "      <td>43954.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26779.0</td>\n",
              "      <td>28389.0</td>\n",
              "      <td>30789.0</td>\n",
              "      <td>33747.0</td>\n",
              "      <td>36581.0</td>\n",
              "      <td>37870.0</td>\n",
              "      <td>39089.0</td>\n",
              "      <td>40517.0</td>\n",
              "      <td>40709.0</td>\n",
              "      <td>39906.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 22:00:00</th>\n",
              "      <td>41552.0</td>\n",
              "      <td>43256.0</td>\n",
              "      <td>44057.0</td>\n",
              "      <td>45641.0</td>\n",
              "      <td>46760.0</td>\n",
              "      <td>46816.0</td>\n",
              "      <td>46989.0</td>\n",
              "      <td>47154.0</td>\n",
              "      <td>46534.0</td>\n",
              "      <td>45372.0</td>\n",
              "      <td>...</td>\n",
              "      <td>25675.0</td>\n",
              "      <td>26779.0</td>\n",
              "      <td>28389.0</td>\n",
              "      <td>30789.0</td>\n",
              "      <td>33747.0</td>\n",
              "      <td>36581.0</td>\n",
              "      <td>37870.0</td>\n",
              "      <td>39089.0</td>\n",
              "      <td>40517.0</td>\n",
              "      <td>40709.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 23:00:00</th>\n",
              "      <td>38500.0</td>\n",
              "      <td>41552.0</td>\n",
              "      <td>43256.0</td>\n",
              "      <td>44057.0</td>\n",
              "      <td>45641.0</td>\n",
              "      <td>46760.0</td>\n",
              "      <td>46816.0</td>\n",
              "      <td>46989.0</td>\n",
              "      <td>47154.0</td>\n",
              "      <td>46534.0</td>\n",
              "      <td>...</td>\n",
              "      <td>25200.0</td>\n",
              "      <td>25675.0</td>\n",
              "      <td>26779.0</td>\n",
              "      <td>28389.0</td>\n",
              "      <td>30789.0</td>\n",
              "      <td>33747.0</td>\n",
              "      <td>36581.0</td>\n",
              "      <td>37870.0</td>\n",
              "      <td>39089.0</td>\n",
              "      <td>40517.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-03 00:00:00</th>\n",
              "      <td>35486.0</td>\n",
              "      <td>38500.0</td>\n",
              "      <td>41552.0</td>\n",
              "      <td>43256.0</td>\n",
              "      <td>44057.0</td>\n",
              "      <td>45641.0</td>\n",
              "      <td>46760.0</td>\n",
              "      <td>46816.0</td>\n",
              "      <td>46989.0</td>\n",
              "      <td>47154.0</td>\n",
              "      <td>...</td>\n",
              "      <td>25479.0</td>\n",
              "      <td>25200.0</td>\n",
              "      <td>25675.0</td>\n",
              "      <td>26779.0</td>\n",
              "      <td>28389.0</td>\n",
              "      <td>30789.0</td>\n",
              "      <td>33747.0</td>\n",
              "      <td>36581.0</td>\n",
              "      <td>37870.0</td>\n",
              "      <td>39089.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145266 rows × 101 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-90d512a4-4d46-485c-8f52-43835a9fb771')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-90d512a4-4d46-485c-8f52-43835a9fb771 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-90d512a4-4d46-485c-8f52-43835a9fb771');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                       value     lag1     lag2     lag3     lag4     lag5  \\\n",
              "Datetime                                                                    \n",
              "2002-01-05 05:00:00  26822.0  26669.0  27034.0  27501.0  28635.0  30924.0   \n",
              "2002-01-05 06:00:00  27399.0  26822.0  26669.0  27034.0  27501.0  28635.0   \n",
              "2002-01-05 07:00:00  28557.0  27399.0  26822.0  26669.0  27034.0  27501.0   \n",
              "2002-01-05 08:00:00  29709.0  28557.0  27399.0  26822.0  26669.0  27034.0   \n",
              "2002-01-05 09:00:00  31241.0  29709.0  28557.0  27399.0  26822.0  26669.0   \n",
              "...                      ...      ...      ...      ...      ...      ...   \n",
              "2018-08-02 20:00:00  44057.0  45641.0  46760.0  46816.0  46989.0  47154.0   \n",
              "2018-08-02 21:00:00  43256.0  44057.0  45641.0  46760.0  46816.0  46989.0   \n",
              "2018-08-02 22:00:00  41552.0  43256.0  44057.0  45641.0  46760.0  46816.0   \n",
              "2018-08-02 23:00:00  38500.0  41552.0  43256.0  44057.0  45641.0  46760.0   \n",
              "2018-08-03 00:00:00  35486.0  38500.0  41552.0  43256.0  44057.0  45641.0   \n",
              "\n",
              "                        lag6     lag7     lag8     lag9  ...    lag91  \\\n",
              "Datetime                                                 ...            \n",
              "2002-01-05 05:00:00  33202.0  35368.0  36762.0  37539.0  ...  30692.0   \n",
              "2002-01-05 06:00:00  30924.0  33202.0  35368.0  36762.0  ...  31395.0   \n",
              "2002-01-05 07:00:00  28635.0  30924.0  33202.0  35368.0  ...  31496.0   \n",
              "2002-01-05 08:00:00  27501.0  28635.0  30924.0  33202.0  ...  31031.0   \n",
              "2002-01-05 09:00:00  27034.0  27501.0  28635.0  30924.0  ...  30360.0   \n",
              "...                      ...      ...      ...      ...  ...      ...   \n",
              "2018-08-02 20:00:00  46534.0  45372.0  43954.0  42189.0  ...  28389.0   \n",
              "2018-08-02 21:00:00  47154.0  46534.0  45372.0  43954.0  ...  26779.0   \n",
              "2018-08-02 22:00:00  46989.0  47154.0  46534.0  45372.0  ...  25675.0   \n",
              "2018-08-02 23:00:00  46816.0  46989.0  47154.0  46534.0  ...  25200.0   \n",
              "2018-08-03 00:00:00  46760.0  46816.0  46989.0  47154.0  ...  25479.0   \n",
              "\n",
              "                       lag92    lag93    lag94    lag95    lag96    lag97  \\\n",
              "Datetime                                                                    \n",
              "2002-01-05 05:00:00  29943.0  29595.0  29308.0  28654.0  28057.0  27899.0   \n",
              "2002-01-05 06:00:00  30692.0  29943.0  29595.0  29308.0  28654.0  28057.0   \n",
              "2002-01-05 07:00:00  31395.0  30692.0  29943.0  29595.0  29308.0  28654.0   \n",
              "2002-01-05 08:00:00  31496.0  31395.0  30692.0  29943.0  29595.0  29308.0   \n",
              "2002-01-05 09:00:00  31031.0  31496.0  31395.0  30692.0  29943.0  29595.0   \n",
              "...                      ...      ...      ...      ...      ...      ...   \n",
              "2018-08-02 20:00:00  30789.0  33747.0  36581.0  37870.0  39089.0  40517.0   \n",
              "2018-08-02 21:00:00  28389.0  30789.0  33747.0  36581.0  37870.0  39089.0   \n",
              "2018-08-02 22:00:00  26779.0  28389.0  30789.0  33747.0  36581.0  37870.0   \n",
              "2018-08-02 23:00:00  25675.0  26779.0  28389.0  30789.0  33747.0  36581.0   \n",
              "2018-08-03 00:00:00  25200.0  25675.0  26779.0  28389.0  30789.0  33747.0   \n",
              "\n",
              "                       lag98    lag99   lag100  \n",
              "Datetime                                        \n",
              "2002-01-05 05:00:00  28357.0  29265.0  30393.0  \n",
              "2002-01-05 06:00:00  27899.0  28357.0  29265.0  \n",
              "2002-01-05 07:00:00  28057.0  27899.0  28357.0  \n",
              "2002-01-05 08:00:00  28654.0  28057.0  27899.0  \n",
              "2002-01-05 09:00:00  29308.0  28654.0  28057.0  \n",
              "...                      ...      ...      ...  \n",
              "2018-08-02 20:00:00  40709.0  39906.0  38637.0  \n",
              "2018-08-02 21:00:00  40517.0  40709.0  39906.0  \n",
              "2018-08-02 22:00:00  39089.0  40517.0  40709.0  \n",
              "2018-08-02 23:00:00  37870.0  39089.0  40517.0  \n",
              "2018-08-03 00:00:00  36581.0  37870.0  39089.0  \n",
              "\n",
              "[145266 rows x 101 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def generate_time_lags(df, n_lags):\n",
        "    df_n = df.copy()\n",
        "    for n in range(1, n_lags + 1):\n",
        "        df_n[f\"lag{n}\"] = df_n[\"value\"].shift(n)\n",
        "    df_n = df_n.iloc[n_lags:]\n",
        "    return df_n\n",
        "\n",
        "input_dim = 100\n",
        "\n",
        "df_timelags = generate_time_lags(df, input_dim)\n",
        "df_timelags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIYvi8YYPA8y"
      },
      "source": [
        "## Splitting the data into test, validation, and train sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0p-cXdOPA8y"
      },
      "source": [
        "After creating feature columns, be it time-lagged observations or date/time features, we split the dataset into three different datasets: training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbqYS89IPA8y"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def feature_label_split(df, target_col):\n",
        "    y = df[[target_col]]\n",
        "    X = df.drop(columns=[target_col])\n",
        "    return X, y\n",
        "\n",
        "def train_val_test_split(df, target_col, test_ratio):\n",
        "    val_ratio = test_ratio / (1 - test_ratio)\n",
        "    X, y = feature_label_split(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df_timelags, 'value', 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j31fX-ztPA8y"
      },
      "source": [
        "### Applying scale transformation\n",
        "\n",
        "Scaling the values in your dataset is a highly recommended practice for neural networks, as it is for other machine learning techniques. It speeds up the learning by making it easier for the model to update the weights. You can easily do that by using Scikit-learn's scalers, MinMaxScaler, RobustScaler, StandardScaler, and the like. For more information on the effects of each scaler, please refer to the official documentation.\n",
        "\n",
        "And, here is a cool trick if you're looking for a way to switch between scalers quickly. Get yourself comfortable with the switcher function; we may use it again later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMO3hUZfPA8y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
        "\n",
        "def get_scaler(scaler):\n",
        "    scalers = {\n",
        "        \"minmax\": MinMaxScaler,\n",
        "        \"standard\": StandardScaler,\n",
        "        \"maxabs\": MaxAbsScaler,\n",
        "        \"robust\": RobustScaler,\n",
        "    }\n",
        "    return scalers.get(scaler.lower())()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwwUAlfVPA8y"
      },
      "outputs": [],
      "source": [
        "scaler = get_scaler('minmax')\n",
        "X_train_arr = scaler.fit_transform(X_train)\n",
        "X_val_arr = scaler.transform(X_val)\n",
        "X_test_arr = scaler.transform(X_test)\n",
        "\n",
        "y_train_arr = scaler.fit_transform(y_train)\n",
        "y_val_arr = scaler.transform(y_val)\n",
        "y_test_arr = scaler.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbFTY8x6PA8y"
      },
      "source": [
        "### Loading the data into DataLoaders\n",
        "\n",
        "After you standardize your data, you are usually good to go. Not so fast, this time. After spending quite some time working with PyTorch and going through others' code on the internet, I noticed most people ended up doing the matrix operations for mini-batch training, i.e., slicing the data into smaller batches, using NumPy. You may think that's what NumPy is for; I get it. But there is also a more elegant PyTorch way of doing it, which certainly gets much less attention than it should, in my opinion.\n",
        "\n",
        "PyTorch's DataLoader class, a Python iterable over Dataset, loads the data and splits them into batches for you to do mini-batch training. The most important argument for the DataLoader constructor is the Dataset, which indicates a dataset object to load data from. There are mainly two types of datasets, one being map-style datasets and the other iterable-style datasets. \n",
        "\n",
        "In this tutorial, I'll use the latter, but feel free to check them out in [the official documentation](https://pytorch.org/docs/stable/data.html). It is also possible to write your own Dataset or DataLoader classes for your requirements, but that's definitely beyond the scope of this post as the built-in constructors would do more than suffice. But here's a link to the official tutorial on the topic.\n",
        "\n",
        "For now, I'll be using the class called TensorDataset, a dataset class wrapping the tensors. Since Scikit-learn's scalers output NumPy arrays, I need to convert them into Torch tensors to load them into TensorDatasets. After creating Tensor datasets for each dataset, I'll use them to create my DataLoaders. You may notice an extra DataLoader with the batch size of 1 and wonder why the hell we need it. I'll get to that in a bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5moZTuRoPA8z"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_features = torch.Tensor(X_train_arr)\n",
        "train_targets = torch.Tensor(y_train_arr)\n",
        "val_features = torch.Tensor(X_val_arr)\n",
        "val_targets = torch.Tensor(y_val_arr)\n",
        "test_features = torch.Tensor(X_test_arr)\n",
        "test_targets = torch.Tensor(y_test_arr)\n",
        "\n",
        "train = TensorDataset(train_features, train_targets)\n",
        "val = TensorDataset(val_features, val_targets)\n",
        "test = TensorDataset(test_features, test_targets)\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSkx5XJzPA8z"
      },
      "source": [
        "## Defining the RNN model classes\n",
        "\n",
        "I don't think I can ever do justice to RNNs if I try to explain the nitty-gritty of how they work in just a few sentences here. Fortunately, there are several well-written articles on these networks for those who are looking for a place to start, Andrej Karpathy's [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), Chris Olah's [Understanding LSTM networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), and Michael Phi's [Illustrated Guide to LSTM's and GRU's: A step by step explanation](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21) are a few that come to mind.\n",
        "\n",
        "However, traditional neural networks can't do this, and they start from scratch every time they are given a task, pretty much like Leonard, you see. RNN addresses this shortcoming. To make a gross oversimplification, they do so by looping the information from one step of the network to the next, allowing information to persist within the network. This makes them a pretty strong candidate to solve various problems involving sequential data, such as speech recognition, language translation, or time-series forecasting, as we will see in a bit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG8osepdR5Mf"
      },
      "source": [
        "### Vanilla RNN\n",
        "By extending PyTorch's nn.Module, a base class for all neural network modules, we define our RNN module as follows. Our RNN module will have one or more RNN layers connected by a fully connected layer to convert the RNN output into desired output shape. We also need to define the forward propagation function as a class method, called forward(). This method is executed sequentially, passing the inputs and the zero-initialized hidden state. Nonetheless, PyTorch automatically creates and computes the backpropagation function backward()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7mN8X9iPA8z"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        \"\"\"The __init__ method that initiates an RNN instance.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): The number of nodes in the input layer\n",
        "            hidden_dim (int): The number of nodes in each layer\n",
        "            layer_dim (int): The number of layers in the network\n",
        "            output_dim (int): The number of nodes in the output layer\n",
        "            dropout_prob (float): The probability of nodes being dropped out\n",
        "\n",
        "        \"\"\"\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # RNN layers\n",
        "        self.rnn = nn.RNN(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"The forward method takes input tensor x and does forward propagation\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor of the shape (batch size, sequence length, input_dim)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor of the shape (batch size, output_dim)\n",
        "\n",
        "        \"\"\"\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, h0 = self.rnn(x, h0.detach())\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[:, -1, :]\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp1ytn5EPA8z"
      },
      "source": [
        "## Making predictions\n",
        "\n",
        "Let's start by creating the main framework for training the models. There are probably heaps of ways to do this, and one of them is to use a helper, or a wrapper, class that holds the training, validation, and evaluation methods. First, we need to have a model class, a loss function to calculate the losses, and an optimizer to update the weights in the network.\n",
        "\n",
        "### Helper/Wrapper Class for training\n",
        "\n",
        "If you're familiar with neural networks, you already know that training them is a rather repetitive process, looping back and forth between forward-prop and back-prop. I find it useful to have one level of abstraction, a train step function or wrapper, to combine these repetitive steps.\n",
        "\n",
        "After defining one proper training step, we can now move onto writing the training loop where this step function will be called at each epoch. During each epoch in training, there are two stages: training and validation. After each training step, the network's weights are tweaked a bit to minimize the loss function. Then, the validation step will evaluate the current state of the model to see if there has been any improvement after the most recent update. \n",
        "\n",
        "As I'll be using mini-batch training, a training technique where only a portion of data is used at each epoch, there will be two for loops for each stage where a model is trained and validated batch by batch. This usually requires reshaping each batch tensor into the correct input dimensions so that the network can use it as an input.\n",
        "\n",
        "Another important thing to note is to activate the train() mode during training and the eval() mode during the validation. While the train() mode allows the network's weights to be updated, the evaluation () mode signals the model that there is no need to calculate the gradients. Hence, the weights stay the same.\n",
        "\n",
        "Now, we can finally train our model. However, without evaluating these models with a separate test set, i.e., a hold-out set, it would be impossible to tell how the model performs than other models we're building. Much similar to the validation loop in the train() method, we'll define a testing method to evaluate our models as follows.\n",
        "\n",
        "During the training, the loss function outputs are generally a good indicator of whether the model is learning, overfitting, or underfitting. For this reason, we'll be plotting simple loss figures by using the following method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjQQzgrGPA8z"
      },
      "outputs": [],
      "source": [
        "class Optimization:\n",
        "    \"\"\"Optimization is a helper class that allows training, validation, prediction.\n",
        "\n",
        "    Optimization is a helper class that takes model, loss function, optimizer function\n",
        "    learning scheduler (optional), early stopping (optional) as inputs. In return, it\n",
        "    provides a framework to train and validate the models, and to predict future values\n",
        "    based on the models.\n",
        "\n",
        "    Attributes:\n",
        "        model (RNNModel, LSTMModel, GRUModel): Model class created for the type of RNN\n",
        "        loss_fn (torch.nn.modules.Loss): Loss function to calculate the losses\n",
        "        optimizer (torch.optim.Optimizer): Optimizer function to optimize the loss function\n",
        "        train_losses (list[float]): The loss values from the training\n",
        "        val_losses (list[float]): The loss values from the validation\n",
        "        last_epoch (int): The number of epochs that the models is trained\n",
        "    \"\"\"\n",
        "    def __init__(self, model, loss_fn, optimizer):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model (RNNModel, LSTMModel, GRUModel): Model class created for the type of RNN\n",
        "            loss_fn (torch.nn.modules.Loss): Loss function to calculate the losses\n",
        "            optimizer (torch.optim.Optimizer): Optimizer function to optimize the loss function\n",
        "        \"\"\"\n",
        "        self.model = model.to(device)\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        \n",
        "    def train_step(self, x, y):\n",
        "        \"\"\"The method train_step completes one step of training.\n",
        "\n",
        "        Given the features (x) and the target values (y) tensors, the method completes\n",
        "        one step of the training. First, it activates the train mode to enable back prop.\n",
        "        After generating predicted values (yhat) by doing forward propagation, it calculates\n",
        "        the losses by using the loss function. Then, it computes the gradients by doing\n",
        "        back propagation and updates the weights by calling step() function.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Tensor for features to train one step\n",
        "            y (torch.Tensor): Tensor for target values to calculate losses\n",
        "\n",
        "        \"\"\"\n",
        "        # Sets model to train mode\n",
        "        self.model.train()\n",
        "\n",
        "        # Makes predictions\n",
        "        yhat = self.model(x)\n",
        "\n",
        "        # Computes loss\n",
        "        loss = self.loss_fn(y, yhat)\n",
        "\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Updates parameters and zeroes gradients\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "\n",
        "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
        "        \"\"\"The method train performs the model training\n",
        "\n",
        "        The method takes DataLoaders for training and validation datasets, batch size for\n",
        "        mini-batch training, number of epochs to train, and number of features as inputs.\n",
        "        Then, it carries out the training by iteratively calling the method train_step for\n",
        "        n_epochs times. If early stopping is enabled, then it  checks the stopping condition\n",
        "        to decide whether the training needs to halt before n_epochs steps. Finally, it saves\n",
        "        the model in a designated file path.\n",
        "\n",
        "        Args:\n",
        "            train_loader (torch.utils.data.DataLoader): DataLoader that stores training data\n",
        "            val_loader (torch.utils.data.DataLoader): DataLoader that stores validation data\n",
        "            batch_size (int): Batch size for mini-batch training\n",
        "            n_epochs (int): Number of epochs, i.e., train steps, to train\n",
        "            n_features (int): Number of feature columns\n",
        "\n",
        "        \"\"\"\n",
        "        model_path = f'{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
        "\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            batch_losses = []\n",
        "            for x_batch, y_batch in train_loader:\n",
        "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
        "                y_batch = y_batch.to(device)\n",
        "                loss = self.train_step(x_batch, y_batch)\n",
        "                batch_losses.append(loss)\n",
        "            training_loss = np.mean(batch_losses)\n",
        "            self.train_losses.append(training_loss)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                batch_val_losses = []\n",
        "                for x_val, y_val in val_loader:\n",
        "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
        "                    y_val = y_val.to(device)\n",
        "                    self.model.eval()\n",
        "                    yhat = self.model(x_val)\n",
        "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
        "                    batch_val_losses.append(val_loss)\n",
        "                validation_loss = np.mean(batch_val_losses)\n",
        "                self.val_losses.append(validation_loss)\n",
        "\n",
        "            if (epoch <= 10) | (epoch % 50 == 0):\n",
        "                print(\n",
        "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
        "                )\n",
        "\n",
        "        torch.save(self.model.state_dict(), model_path)\n",
        "\n",
        "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
        "        \"\"\"The method evaluate performs the model evaluation\n",
        "\n",
        "        The method takes DataLoaders for the test dataset, batch size for mini-batch testing,\n",
        "        and number of features as inputs. Similar to the model validation, it iteratively\n",
        "        predicts the target values and calculates losses. Then, it returns two lists that\n",
        "        hold the predictions and the actual values.\n",
        "\n",
        "        Note:\n",
        "            This method assumes that the prediction from the previous step is available at\n",
        "            the time of the prediction, and only does one-step prediction into the future.\n",
        "\n",
        "        Args:\n",
        "            test_loader (torch.utils.data.DataLoader): DataLoader that stores test data\n",
        "            batch_size (int): Batch size for mini-batch training\n",
        "            n_features (int): Number of feature columns\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The values predicted by the model\n",
        "            list[float]: The actual values in the test set.\n",
        "\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            predictions = []\n",
        "            values = []\n",
        "            for x_test, y_test in test_loader:\n",
        "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
        "                y_test = y_test.to(device)\n",
        "                self.model.eval()\n",
        "                yhat = self.model(x_test)\n",
        "                predictions.append(yhat.to(device).detach().numpy())\n",
        "                values.append(y_test.to(device).detach().numpy())\n",
        "\n",
        "        return predictions, values\n",
        "\n",
        "    def plot_losses(self):\n",
        "        \"\"\"The method plots the calculated loss values for training and validation\n",
        "        \"\"\"\n",
        "        plt.plot(self.train_losses, label=\"Training loss\")\n",
        "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Losses\")\n",
        "        plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaY3LqC6PA80"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "So far, we have prepared our dataset, defined our model classes and the wrapper class. We need to put all of them together. Without further ado, let's start training our model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "id3qcBi5PA80",
        "outputId": "4ce339fa-8442-4ae6-f119-e43211e7c04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/20] Training loss: 0.0046\t Validation loss: 0.0077\n",
            "[2/20] Training loss: 0.0027\t Validation loss: 0.0054\n",
            "[3/20] Training loss: 0.0018\t Validation loss: 0.0025\n",
            "[4/20] Training loss: 0.0013\t Validation loss: 0.0011\n",
            "[5/20] Training loss: 0.0012\t Validation loss: 0.0008\n",
            "[6/20] Training loss: 0.0011\t Validation loss: 0.0008\n",
            "[7/20] Training loss: 0.0010\t Validation loss: 0.0007\n",
            "[8/20] Training loss: 0.0009\t Validation loss: 0.0006\n",
            "[9/20] Training loss: 0.0009\t Validation loss: 0.0007\n",
            "[10/20] Training loss: 0.0009\t Validation loss: 0.0008\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "input_dim = len(X_train.columns)\n",
        "output_dim = 1\n",
        "hidden_dim = 64\n",
        "layer_dim = 3\n",
        "batch_size = 64\n",
        "dropout = 0.2\n",
        "n_epochs = 20\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6\n",
        "\n",
        "model_params = {'input_dim': input_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout}\n",
        "\n",
        "model = RNNModel(**model_params)\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
        "opt.plot_losses()\n",
        "\n",
        "predictions, values = opt.evaluate(\n",
        "    test_loader_one,\n",
        "    batch_size=1,\n",
        "    n_features=input_dim\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH44v1oZPA80"
      },
      "source": [
        "### Formatting the predictions\n",
        "\n",
        "As you may recall, we trained our network with standardized inputs; therefore, all the model's predictions are also scaled. Also, after using batching in our evaluation method, all of our predictions are now in batches. To calculate error metrics and plot these predictions, we need first to reduce these multi-dimensional tensors to a one-dimensional vector, i.e., flatten, and then apply inverse_transform() to get the predictions' real values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "1SuCqBPzPA80",
        "outputId": "5aad7064-4631-4dbb-f385-05ef1e7239a9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c697f2cf-0e63-42ab-a7c6-e3c38190212a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>value</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-04-10 11:00:00</th>\n",
              "      <td>32296.000000</td>\n",
              "      <td>32963.476562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-10 12:00:00</th>\n",
              "      <td>31941.000000</td>\n",
              "      <td>32564.544922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-10 13:00:00</th>\n",
              "      <td>31488.000000</td>\n",
              "      <td>32050.283203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-10 14:00:00</th>\n",
              "      <td>31067.998047</td>\n",
              "      <td>31640.558594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-04-10 15:00:00</th>\n",
              "      <td>30483.000000</td>\n",
              "      <td>31322.837891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 20:00:00</th>\n",
              "      <td>44057.000000</td>\n",
              "      <td>42816.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 21:00:00</th>\n",
              "      <td>43256.000000</td>\n",
              "      <td>41400.613281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 22:00:00</th>\n",
              "      <td>41552.000000</td>\n",
              "      <td>40084.664062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-02 23:00:00</th>\n",
              "      <td>38500.000000</td>\n",
              "      <td>37847.496094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-08-03 00:00:00</th>\n",
              "      <td>35486.000000</td>\n",
              "      <td>35120.519531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29054 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c697f2cf-0e63-42ab-a7c6-e3c38190212a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c697f2cf-0e63-42ab-a7c6-e3c38190212a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c697f2cf-0e63-42ab-a7c6-e3c38190212a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                            value    prediction\n",
              "Datetime                                       \n",
              "2015-04-10 11:00:00  32296.000000  32963.476562\n",
              "2015-04-10 12:00:00  31941.000000  32564.544922\n",
              "2015-04-10 13:00:00  31488.000000  32050.283203\n",
              "2015-04-10 14:00:00  31067.998047  31640.558594\n",
              "2015-04-10 15:00:00  30483.000000  31322.837891\n",
              "...                           ...           ...\n",
              "2018-08-02 20:00:00  44057.000000  42816.937500\n",
              "2018-08-02 21:00:00  43256.000000  41400.613281\n",
              "2018-08-02 22:00:00  41552.000000  40084.664062\n",
              "2018-08-02 23:00:00  38500.000000  37847.496094\n",
              "2018-08-03 00:00:00  35486.000000  35120.519531\n",
              "\n",
              "[29054 rows x 2 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def inverse_transform(scaler, df, columns):\n",
        "    for col in columns:\n",
        "        df[col] = scaler.inverse_transform(df[col])\n",
        "    return df\n",
        "\n",
        "\n",
        "def format_predictions(predictions, values, df_test, scaler):\n",
        "    vals = np.concatenate(values, axis=0).ravel()\n",
        "    preds = np.concatenate(predictions, axis=0).ravel()\n",
        "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
        "    df_result = df_result.sort_index()\n",
        "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
        "    return df_result\n",
        "\n",
        "\n",
        "df_result = format_predictions(predictions, values, X_test, scaler)\n",
        "df_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7qX7JmyPA80"
      },
      "source": [
        "### Calculating error metrics\n",
        "\n",
        "After flattening and de-scaling the values, we can now calculate error metrics, such as mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fWEUu-3PA80",
        "outputId": "d83c688a-5ca0-40aa-f83f-aa9aac36b745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error:        772.2306\n",
            "Root Mean Squared Error:    980.3157335777081\n",
            "R^2 Score:                  0.9771873301517322\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "def calculate_metrics(df):\n",
        "    result_metrics = {'mae' : mean_absolute_error(df.value, df.prediction),\n",
        "                      'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,\n",
        "                      'r2' : r2_score(df.value, df.prediction)}\n",
        "    \n",
        "    print(\"Mean Absolute Error:       \", result_metrics[\"mae\"])\n",
        "    print(\"Root Mean Squared Error:   \", result_metrics[\"rmse\"])\n",
        "    print(\"R^2 Score:                 \", result_metrics[\"r2\"])\n",
        "    return result_metrics\n",
        "\n",
        "result_metrics = calculate_metrics(df_result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pQ0Ia7uTre8"
      },
      "source": [
        "### Generating baseline predictions\n",
        "\n",
        "Having some sort of baseline model helps us compare how our models actually do at prediction. For this task, I've chosen good old linear regression, good enough to generate reasonable baseline but simple enough to do it very fast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUr2qd5FtbGQ",
        "outputId": "c7799bc1-e505-4476-88e5-34da704ed1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error:        202.1403806979192\n",
            "Root Mean Squared Error:    281.47269392124565\n",
            "R^2 Score:                  0.9981193123175233\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def build_baseline_model(df, test_ratio, target_col):\n",
        "    X, y = feature_label_split(df, target_col)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_ratio, shuffle=False\n",
        "    )\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "    prediction = model.predict(X_test)\n",
        "\n",
        "    result = pd.DataFrame(y_test)\n",
        "    result[\"prediction\"] = prediction\n",
        "    result = result.sort_index()\n",
        "\n",
        "    return result\n",
        "\n",
        "df_baseline = build_baseline_model(df_timelags, 0.2, 'value')\n",
        "baseline_metrics = calculate_metrics(df_baseline)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtuJ2yIetabf"
      },
      "source": [
        "### Visualizing the predictions\n",
        "\n",
        "Last but not least, visualizing your results helps you better understand how your model performs and adds what kind of features would likely improve it. I'll be using Plotly again, but feel free to use a package that you are more comfortable with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fsrbbhuzPA81",
        "outputId": "cc37bd60-f956-4490-efc7-1a1fff8f3a5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f530d8c1d00>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_result.plot()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c9469ccdb9909bf8ae53e53989a83866ae2608bf3b53aa81908df53e67f16189"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
